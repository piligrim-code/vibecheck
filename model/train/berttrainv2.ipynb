{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e8bd97f-7a83-4e81-9d3f-4cd9438cd9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, trange\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import clearml\n",
    "from clearml import Task, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b7fb25-c84e-43e8-870c-d1e523d6827b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.739</td>\n",
       "      <td>Все на питоне</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.245</td>\n",
       "      <td>Ребят, а как хантеры относятся к начинающим ст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.234</td>\n",
       "      <td>Ни разу не сказали, что берут для повышения оц...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.152</td>\n",
       "      <td>А прям точно нужна кластеризация? Возможно, пр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120</td>\n",
       "      <td>на расчет метрик, придумываете новых, на аб тесты</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.500</td>\n",
       "      <td>это норм. фильтруется таблица и после этого то...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.200</td>\n",
       "      <td>а это вы на ml-инженера или на data аналитика ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>-0.300</td>\n",
       "      <td>lms по этой же причине не отрывается?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>-0.125</td>\n",
       "      <td>вообще я думал через and написать и в date_par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.200</td>\n",
       "      <td>это решение уже обнаружил) вдруг есть что то д...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment_score                                            message\n",
       "0                0.739                                      Все на питоне\n",
       "1                0.245  Ребят, а как хантеры относятся к начинающим ст...\n",
       "2               -0.234  Ни разу не сказали, что берут для повышения оц...\n",
       "3                0.152  А прям точно нужна кластеризация? Возможно, пр...\n",
       "4                0.120  на расчет метрик, придумываете новых, на аб тесты\n",
       "...                ...                                                ...\n",
       "29995            0.500  это норм. фильтруется таблица и после этого то...\n",
       "29996            0.200  а это вы на ml-инженера или на data аналитика ...\n",
       "29997           -0.300              lms по этой же причине не отрывается?\n",
       "29998           -0.125  вообще я думал через and написать и в date_par...\n",
       "29999            0.200  это решение уже обнаружил) вдруг есть что то д...\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv('C://Users//milai/Downloads/data2.csv')\n",
    "df = df_1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18c0076e-1609-4a62-87e6-c1284131b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoyoMeterDataset(Dataset):\n",
    "    def __init__(self, features, target):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index): \n",
    "        feature = self.features[index]\n",
    "        target = self.target[index]\n",
    "        return feature, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb84bb3e-6e27-4675-890c-74800603a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message'].reset_index(drop=True)\n",
    "y = df['sentiment_score'].reset_index(drop=True)\n",
    "\n",
    "# Правильное разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, shuffle=True)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "train_dataset = JoyoMeterDataset(X_train, y_train)\n",
    "val_dataset = JoyoMeterDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a629e363-93f4-43df-8556-0588ea72788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from joblib import Memory\n",
    "\n",
    "memory = Memory(\"cache_dir\", verbose=0)\n",
    "\n",
    "\n",
    "class BertRegression(nn.Module):\n",
    "    def __init__(self,\n",
    "                 model_name=\"DeepPavlov/rubert-base-cased\",\n",
    "                 pretrained_weights_path=\"destination_filename.pth\"):\n",
    "        super(BertRegression, self).__init__()\n",
    "        \n",
    "        torch.manual_seed(50) \n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.bert.to(torch.device('cpu'))\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.layer_norm = nn.LayerNorm(self.bert.config.hidden_size)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(self.bert.config.hidden_size, 256), nn.Tanh(),\n",
    "            nn.Linear(256, 1))\n",
    "\n",
    "        self.load_state_dict(\n",
    "            torch.load(pretrained_weights_path,\n",
    "                       map_location=torch.device('cpu'),\n",
    "                       weights_only=True))\n",
    "\n",
    "        self.device = 'cpu'\n",
    "        self.to(self.device)\n",
    "\n",
    "    @memory.cache(ignore=['self'])\n",
    "    def tokenize(self, input_text):\n",
    "        return self.tokenizer(input_text,\n",
    "                              return_tensors=\"pt\",\n",
    "                              max_length=512,\n",
    "                              truncation=True,\n",
    "                              padding='max_length')\n",
    "\n",
    "    def predict(self, input_text):\n",
    "        with torch.no_grad():\n",
    "            tokens = self.tokenize(self, input_text)\n",
    "            input_ids = tokens[\"input_ids\"].to(self.device)\n",
    "            attention_mask = tokens[\"attention_mask\"].to(self.device)\n",
    "            outputs = self.bert(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "            pooled_output = outputs.pooler_output\n",
    "            dropout_output = self.dropout(pooled_output)\n",
    "            layer_norm_output = self.layer_norm(dropout_output)\n",
    "            linear_output = self.regressor(layer_norm_output)\n",
    "            return linear_output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6dd093d-c56d-4da2-a7e2-163fd8b680bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertRegression(device='cpu')\n",
    "epochs = 5\n",
    "accumulation_steps = 4\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3850d5f-ea51-48f7-99b9-9983fe04a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3e9e304-94eb-4c78-8c7a-7b159d90596b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: -0.38380342721939087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MY_PROGRAMMIER_SLOTS\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "bert_regression_model.load_state_dict(torch.load('bertweight2new2.pth'))\n",
    "bert_regression_model.to(device)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = 'cuda'\n",
    "def predict(text, model, tokenizer, device):\n",
    "  \"\"\"\n",
    "  Функция для предсказания модели BERT для заданного текста.\n",
    "\n",
    "  Args:\n",
    "      text: Текст для предсказания.\n",
    "      model: Модель BERT (BertRegression).\n",
    "      tokenizer: Токенизатор для BERT.\n",
    "      device: Устройство для вычислений (CPU или GPU).\n",
    "\n",
    "  Returns:\n",
    "      Предсказанное непрерывное значение.\n",
    "  \"\"\"\n",
    "\n",
    "  # Токенизация текста\n",
    "  inputs = tokenizer_deep(text, return_tensors=\"pt\", add_special_tokens=True, padding=True).to(device)\n",
    "\n",
    "  # Вывод модели\n",
    "  with torch.no_grad():\n",
    "    outputs = model(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "    )\n",
    "\n",
    "  # Получение предсказания\n",
    "  output = outputs.squeeze().item()  # Извлекаем выход из последнего слоя (полносвязный)\n",
    "  return output\n",
    "\n",
    "# Пример использования:\n",
    "text =  \"да ебать вас\"\n",
    "predicted_value = predict(text, bert_regression_model, tokenizer_deep, device) \n",
    "print(f\"Predicted value: {predicted_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11cb64a-8833-41a3-b859-2a643209e884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=3d64ef93274d49da830909d8f397d399\n",
      "ClearML results page: https://app.clear.ml/projects/f857a6e643a74a039cefea4c76612313/experiments/3d64ef93274d49da830909d8f397d399/output/log\n",
      "2024-08-30 22:23:34,445 - clearml.Task - INFO - Storing jupyter notebook directly as code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|                                                                               | 0/410 [00:00<?, ?it/s]D:\\MY_PROGRAMMIER_SLOTS\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Epoch 1/5:  38%|██████████████████████████▍                                          | 157/410 [02:43<02:17,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.108, Train RMSE: 0.323, Val Loss: 0.093, Val RMSE: 0.293\n",
      "ClearML Monitor: Reporting detected, reverting back to iteration based reporting\n",
      "2024-08-30 22:33:43,459 - clearml.frameworks - INFO - Found existing registered model id=e7794abf28814d84835d3ff98a911e80 [C:\\Users\\milai\\bertweight2new2.pth] reusing it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.079, Train RMSE: 0.275, Val Loss: 0.093, Val RMSE: 0.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.059, Train RMSE: 0.238, Val Loss: 0.081, Val RMSE: 0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.043, Train RMSE: 0.202, Val Loss: 0.084, Val RMSE: 0.280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.035, Train RMSE: 0.181, Val Loss: 0.101, Val RMSE: 0.310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "██████████████████████████████ 100% | 679.30/679.3 MB [29:00<00:00,  2.56s/MB]: D:\\MY_PROGRAMMIER_SLOTS\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:636: TqdmWarning: clamping frac to range [0, 1]\n",
      "  full_bar = Bar(frac,\n",
      "██████████████████████████████ 100% | 679.30/679.3 MB [29:09<00:00,  2.57s/MB]: \n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "def calculate_rmse(outputs, scores, criterion):\n",
    "    \"\"\"Вычисляет RMSE для заданных выходов и меток.\"\"\"\n",
    "    rmse = torch.sqrt(criterion(outputs.squeeze(), scores.to(device).float())).mean()\n",
    "    return rmse.item()\n",
    "\n",
    "def train_step(model, optimizer, criterion, dataloader, epoch, device):\n",
    "    \"\"\"Обучение модели на одной эпохе.\"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_rmse = 0.0\n",
    "    train_len = len(dataloader)\n",
    "    for tweets, scores in tqdm(dataloader, total=train_len, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "        inputs = tokenizer_deep.batch_encode_plus(\n",
    "            tweets,\n",
    "            return_tensors='pt',\n",
    "            add_special_tokens=True,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        ).to(device)\n",
    "\n",
    "        # Получение предсказаний\n",
    "        outputs = model(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask)\n",
    "\n",
    "        # Вычисление потерь и обратное распространение\n",
    "        loss = criterion(outputs.squeeze(), scores.to(device).float()).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_rmse += calculate_rmse(outputs, scores, criterion)\n",
    "\n",
    "    train_loss_avg = train_loss / train_len\n",
    "    train_rmse_avg = train_rmse / train_len\n",
    "    return train_loss_avg, train_rmse_avg\n",
    "\n",
    "def validation_step(model, criterion, dataloader, epoch, device):\n",
    "    \"\"\"Оценка модели на валидационных данных.\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_rmse = 0\n",
    "    val_len = len(dataloader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for tweets, scores in tqdm(dataloader, total=val_len, desc=f\"Validation\", leave=False):\n",
    "            inputs = tokenizer_deep.batch_encode_plus(\n",
    "                tweets,\n",
    "                return_tensors='pt',\n",
    "                add_special_tokens=True,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            ).to(device)\n",
    "\n",
    "            # Получение предсказаний\n",
    "            outputs = model(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask)\n",
    "\n",
    "            # Вычисление потерь\n",
    "            val_loss += criterion(outputs.squeeze(), scores.to(device).float()).item()\n",
    "            val_rmse += calculate_rmse(outputs, scores, criterion)\n",
    "\n",
    "    val_loss_avg = val_loss / val_len\n",
    "    val_rmse_avg = val_rmse / val_len\n",
    "    return val_loss_avg, val_rmse_avg\n",
    "\n",
    "task = Task.init(project_name='Bertv2', task_name='BertTrain')\n",
    "logger = Logger.current_logger()\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Цикл обучения\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_rmse = train_step(bert_regression_model, optimizer, criterion, train_dataloader, epoch, device)\n",
    "    val_loss, val_rmse = validation_step(bert_regression_model, criterion, val_dataloader, epoch, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.3f}, Train RMSE: {train_rmse:.3f}, Val Loss: {val_loss:.3f}, Val RMSE: {val_rmse:.3f}\")\n",
    "\n",
    "    # Логирование метрик в ClearML\n",
    "    logger.report_scalar(title='Train Loss', series='loss', value=train_loss, iteration=epoch)\n",
    "    logger.report_scalar(title='Train RMSE', series='rmse', value=train_rmse, iteration=epoch)\n",
    "    logger.report_scalar(title='Validation Loss', series='loss', value=val_loss, iteration=epoch)\n",
    "    logger.report_scalar(title='Validation RMSE', series='rmse', value=val_rmse, iteration=epoch)\n",
    "\n",
    "    # Сохранение модели\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(bert_regression_model.state_dict(), 'bertweight2new2.pth')\n",
    "    if epoch == epochs - 1:  # Проверяем,  последняя ли это эпоха\n",
    "        torch.save(bert_regression_model.state_dict(), 'bertweight2new2last.pth')\n",
    "        task.upload_artifact('model', 'bertweight2new2last.pth')\n",
    "\n",
    "# Завершение задачи ClearML\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88081b47-5ec4-42ec-985e-7f4edcd54eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
